# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MGVkjHzQOk6p9EMbRMWjD8NP95jkY8IN
"""

#Import Python Packages
#from google.colab import drive
#drive.mount('/content/drive/')
from google.colab import drive
drive.mount('/gdrive')

#Import all necessary library
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix,classification_report
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn import tree
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

#Read training data file
trainfile = r'/gdrive/MyDrive/ColabNotebooks/TRAIN.csv'
trainData = pd.read_csv(trainfile)

#Read test data file
testfile = r'/gdrive/MyDrive/ColabNotebooks/TEST.csv'
testData = pd.read_csv(testfile)

trainData.head()
#print("=======")
#testData.head()

#To get list of names of all Columns from a dataframe

TrainCols = list(trainData.columns.values)
TestCols = list(testData.columns.values)
print(TrainCols)
print(TestCols)

# Seperate Target column from Train Data
Xtrain = trainData[TrainCols[0:len(TrainCols)-1]].copy()
Ytrain = trainData[['TARGET']].copy()
print(Xtrain.shape)
print(Ytrain.shape)
Xtest = testData[TestCols[0:len(TestCols)]].copy()
print(Xtest.shape)
print(Ytrain.value_counts())

# trainData['TARGET'].hist()
# plt.xlabel("Target Score")
# plt.ylabel("Frequency")
# plt.show()
class_distribution = Ytrain.value_counts()
print(class_distribution)
import matplotlib.pyplot as plt
class_distribution.plot(kind='bar')
plt.title('Target Score Histogram')
plt.xlabel('Target scores')
plt.ylabel('Frequency')
plt.show()

smote = SMOTE(random_state = 20)
xsam, ysam = smote.fit_resample(Xtrain, Ytrain)
print(ysam.value_counts())
X_train, X_test, Y_train, Y_test = train_test_split(xsam, ysam, test_size = .20, random_state = 1)

dt = DecisionTreeClassifier(criterion="entropy", max_depth = 30, max_leaf_nodes = 30, max_features = 40)
dt.fit(X_train, Y_train)
X_Pred = dt.predict(X_test)
#Model Accuracy
print("Accuracy:", metrics.accuracy_score(Y_test,X_Pred))
print(metrics.classification_report(Y_test, X_Pred))
test_pred = dt.predict(testData)
wkk = pd.DataFrame({'ID': testData['ID'], 'TARGET': test_pred})
wkk.to_csv('/content/ML/model1.csv', index=False)

dt = DecisionTreeClassifier(criterion="entropy", max_depth = 60, max_leaf_nodes = 30, max_features = 40)
dt.fit(X_train, Y_train)
X_Pred = dt.predict(X_test)
#Model Accuracy
print("Accuracy:", metrics.accuracy_score(Y_test,X_Pred))
print(metrics.classification_report(Y_test, X_Pred))
test_pred = dt.predict(testData)
wkk = pd.DataFrame({'ID': testData['ID'], 'TARGET': test_pred})
wkk.to_csv('/content/ML/model2.csv', index=False)

dt = DecisionTreeClassifier(criterion="entropy", max_depth = 50, max_leaf_nodes = 30, max_features = 40)
dt.fit(X_train, Y_train)
X_Pred = dt.predict(X_test)
#Model Accuracy
print("Accuracy:", metrics.accuracy_score(Y_test,X_Pred))
print(metrics.classification_report(Y_test, X_Pred))
test_pred = dt.predict(testData)
wkk = pd.DataFrame({'ID': testData['ID'], 'TARGET': test_pred})
wkk.to_csv('/content/ML/model3.csv', index=False)
